{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normative modelling for dMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/braincharts/scripts/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from random import sample\n",
    "\n",
    "from pcntoolkit.normative import estimate, predict, evaluate\n",
    "from pcntoolkit.util.utils import compute_MSLL, create_design_matrix\n",
    "from nm_utils import calibration_descriptives, remove_bad_subjects, load_2d\n",
    "\n",
    "ukb_root = '/project_freenas/3022017.02/UKB'\n",
    "sys.path.append(os.path.join(ukb_root,'scripts'))\n",
    "from ukb_utils import get_variables_UKB, lookup_UKB\n",
    "ukb_idp_dir = os.path.join(ukb_root,'phenotypes','current')\n",
    "root_dir = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/braincharts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sex\n",
    "field_codes = ['eid','31-0.0']\n",
    "field_names = ['eid', 'sex']\n",
    "df_sex, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'01_basic_demographics.csv'), field_codes, field_names)\n",
    "\n",
    "# load age and site\n",
    "field_codes = ['eid', '21003-2.0', '54-2.0']\n",
    "field_names = ['eid', 'age', 'site']\n",
    "df_age, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'99_miscellaneous.csv'), field_codes, field_names)\n",
    "\n",
    "# load dMRI derived phenotypes\n",
    "field_codes = ['eid', '25059-2.0', '25101-2.0']\n",
    "field_names = ['eid', 'FA_corpus_callosum', 'FA_uncinate_fasciculus']\n",
    "df_dmri, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'31_brain_IDPs.csv'), field_codes, field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmri_data = df_sex.join(df_age).join(df_dmri)\n",
    "dmri_data.dropna(inplace=True)\n",
    "dmri_data.to_csv(os.path.join(root_dir,'data_dmri.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the raw data are stored\n",
    "data_dir = os.path.join(root_dir,'data')\n",
    "\n",
    "# where the analysis takes place\n",
    "out_dir = os.path.join(root_dir,'models','test')\n",
    "\n",
    "# create the output directory if it does not already exist\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23158 subjects in total\n",
      "There are 22658 subjects without manually assigned labels\n",
      "There are 17658 subjects for training\n",
      "There are 5000 subjects for testing\n"
     ]
    }
   ],
   "source": [
    "### Load all the subject IDs that have qc data available\n",
    "pickled_data = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/subjects_qc.pkl'\n",
    "with open(pickled_data, 'rb') as f: \n",
    "    subs_qc = pickle.load(f)\n",
    "### Load the subjects IDs that have manual qc labels available \n",
    "pickled_data = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/labeledsubs_qc.pkl'\n",
    "with open(pickled_data, 'rb') as f: \n",
    "    labeled_qc = pickle.load(f)\n",
    "### Subtract the labeled subs from the total subs\n",
    "keys = list(labeled_qc.columns.values)\n",
    "i1 = subs_qc.set_index(keys).index\n",
    "i2 = labeled_qc.set_index(keys).index\n",
    "unlabeled_subs = subs_qc[~i1.isin(i2)]\n",
    "print('There are', len(subs_qc), 'subjects in total')\n",
    "print('There are', len(unlabeled_subs), 'subjects without manually assigned labels')\n",
    "### Split the subjects into training and testing\n",
    "### Select 5k subjects randomly for the testing dataset\n",
    "# unlabeled_subs = unlabeled_subs.subs.tolist()\n",
    "# subs_test = sample(unlabeled_subs,5000)\n",
    "# subs_test = pd.DataFrame(subs_test)\n",
    "# subs_test.columns = ['subs']\n",
    "# subs_test.to_pickle('/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/subs_test_5k.pkl')\n",
    "pickled_data2 = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/subs_test_5k.pkl'\n",
    "with open(pickled_data2, 'rb') as f: \n",
    "    subs_test = pickle.load(f)\n",
    "### Create the training subs list\n",
    "keys = list(subs_test.columns.values)\n",
    "i1 = unlabeled_subs.set_index(keys).index\n",
    "i2 = subs_test.set_index(keys).index\n",
    "subs_train = unlabeled_subs[~i1.isin(i2)]\n",
    "print('There are', len(subs_train), 'subjects for training')\n",
    "print('There are', len(subs_test), 'subjects for testing')\n",
    "# subs_train.to_pickle('/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/subs_train_5k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the training and testig dataset based on the subject lists\n",
    "df_tr = dmri_data[dmri_data.index.isin(subs_train.subs)]\n",
    "df_te = dmri_data[dmri_data.index.isin(subs_test.subs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>site</th>\n",
       "      <th>age</th>\n",
       "      <th>FA_corpus_callosum</th>\n",
       "      <th>FA_uncinate_fasciculus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11025.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.725544</td>\n",
       "      <td>0.570983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11027.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.749954</td>\n",
       "      <td>0.564741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002758</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11027.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.706880</td>\n",
       "      <td>0.493949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004244</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11027.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.752798</td>\n",
       "      <td>0.519203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004617</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11027.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.755851</td>\n",
       "      <td>0.562250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022149</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11025.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.701434</td>\n",
       "      <td>0.466851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023174</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11025.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.518593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023696</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11025.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.746134</td>\n",
       "      <td>0.556581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11025.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.705610</td>\n",
       "      <td>0.506818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025069</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11025.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.686748</td>\n",
       "      <td>0.468932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4998 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex     site   age  FA_corpus_callosum  FA_uncinate_fasciculus\n",
       "eid                                                                    \n",
       "1001815  0.0  11025.0  59.0            0.725544                0.570983\n",
       "1002690  1.0  11027.0  77.0            0.749954                0.564741\n",
       "1002758  1.0  11027.0  60.0            0.706880                0.493949\n",
       "1004244  0.0  11027.0  51.0            0.752798                0.519203\n",
       "1004617  1.0  11027.0  71.0            0.755851                0.562250\n",
       "...      ...      ...   ...                 ...                     ...\n",
       "6022149  1.0  11025.0  67.0            0.701434                0.466851\n",
       "6023174  0.0  11025.0  69.0            0.681440                0.518593\n",
       "6023696  1.0  11025.0  69.0            0.746134                0.556581\n",
       "6023777  0.0  11025.0  73.0            0.705610                0.506818\n",
       "6025069  1.0  11025.0  72.0            0.686748                0.468932\n",
       "\n",
       "[4998 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure which models to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(root_dir,'data','phenotypes.txt')) as f:\n",
    "#     idp_ids = f.read().splitlines()\n",
    "idp_ids = ['FA_corpus_callosum', 'FA_uncinate_fasciculus']\n",
    "site_ids =  sorted(set(df_tr['site'].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which data columns do we wish to use as covariates? \n",
    "cols_cov = ['age','sex']\n",
    "\n",
    "# which warping function to use? We can set this to None in order to fit a vanilla Gaussian noise model\n",
    "warp =  'WarpSinArcsinh'\n",
    "\n",
    "# limits for cubic B-spline basis \n",
    "xmin = -5 \n",
    "xmax = 110\n",
    "\n",
    "# Do we want to force the model to be refit every time? \n",
    "force_refit = True\n",
    "\n",
    "# Absolute Z treshold above which a sample is considered to be an outlier (without fitting any model)\n",
    "outlier_thresh = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IDP 0 FA_corpus_callosum :\n",
      "Estimating the normative model...\n",
      "Processing data in /home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/braincharts/models/test/FA_corpus_callosum/resp_tr.txt\n",
      "Estimating model  1 of 1\n",
      "configuring BLR ( order 1 )\n",
      "Using default hyperparameters\n",
      "Saving model meta-data...\n",
      "Evaluating the model ...\n",
      "Writing outputs ...\n",
      "Running IDP 1 FA_uncinate_fasciculus :\n",
      "Estimating the normative model...\n",
      "Processing data in /home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/braincharts/models/test/FA_uncinate_fasciculus/resp_tr.txt\n",
      "Estimating model  1 of 1\n",
      "configuring BLR ( order 1 )\n",
      "Using default hyperparameters\n",
      "Warning: Estimation of posterior distribution failed\n",
      "Warning: Estimation of posterior distribution failed\n",
      "Warning: Estimation of posterior distribution failed\n",
      "Warning: Estimation of posterior distribution failed\n",
      "Warning: Estimation of posterior distribution failed\n",
      "Saving model meta-data...\n",
      "Evaluating the model ...\n",
      "Writing outputs ...\n"
     ]
    }
   ],
   "source": [
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    print('Running IDP', idp_num, idp, ':')\n",
    "   \n",
    "    # set output dir \n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    os.makedirs(os.path.join(idp_dir), exist_ok=True)\n",
    "    os.chdir(idp_dir)\n",
    "    \n",
    "    # extract the response variables for training and test set\n",
    "    y_tr = df_tr[idp].to_numpy() \n",
    "    y_te = df_te[idp].to_numpy()\n",
    "    \n",
    "    # remove gross outliers and implausible values\n",
    "#     yz_tr = (y_tr - np.mean(y_tr)) / np.std(y_tr)\n",
    "#     yz_te = (y_te - np.mean(y_te)) / np.std(y_te)\n",
    "#     nz_tr = np.bitwise_and(np.abs(yz_tr) < outlier_thresh, y_tr > 0)\n",
    "#     nz_te = np.bitwise_and(np.abs(yz_te) < outlier_thresh, y_te > 0)\n",
    "#     y_tr = y_tr[nz_tr]\n",
    "#     y_te = y_te[nz_te]\n",
    "    \n",
    "    # write out the response variables for training and test\n",
    "    resp_file_tr = os.path.join(idp_dir, 'resp_tr.txt')\n",
    "    resp_file_te = os.path.join(idp_dir, 'resp_te.txt') \n",
    "    np.savetxt(resp_file_tr, y_tr)\n",
    "    np.savetxt(resp_file_te, y_te)\n",
    "        \n",
    "    # configure the design matrix\n",
    "    X_tr = create_design_matrix(df_tr[cols_cov], \n",
    "                                site_ids = df_tr['site'],\n",
    "                                basis = 'bspline', \n",
    "                                xmin = xmin, \n",
    "                                xmax = xmax)\n",
    "    X_te = create_design_matrix(df_te[cols_cov], \n",
    "                                site_ids = df_te['site'], \n",
    "                                all_sites=site_ids,\n",
    "                                basis = 'bspline', \n",
    "                                xmin = xmin, \n",
    "                                xmax = xmax)\n",
    "\n",
    "    # configure and save the covariates\n",
    "    cov_file_tr = os.path.join(idp_dir, 'cov_bspline_tr.txt')\n",
    "    cov_file_te = os.path.join(idp_dir, 'cov_bspline_te.txt')\n",
    "    np.savetxt(cov_file_tr, X_tr)\n",
    "    np.savetxt(cov_file_te, X_te)\n",
    "\n",
    "    if not force_refit and os.path.exists(os.path.join(idp_dir, 'Models', 'NM_0_0_estimate.pkl')):\n",
    "        print('Making predictions using a pre-existing model...')\n",
    "        suffix = 'predict'\n",
    "        \n",
    "        # Make prdictsion with test data\n",
    "        predict(cov_file_te, \n",
    "                alg='blr', \n",
    "                respfile=resp_file_te, \n",
    "                model_path=os.path.join(idp_dir,'Models'),\n",
    "                outputsuffix=suffix)\n",
    "    else:\n",
    "        print('Estimating the normative model...')\n",
    "        estimate(cov_file_tr, resp_file_tr, testresp=resp_file_te, \n",
    "                 testcov=cov_file_te, alg='blr', optimizer = 'l-bfgs-b', \n",
    "                 savemodel=True, warp=warp, warp_reparam=True)\n",
    "        suffix = 'estimate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>NLL</th>\n",
       "      <th>EV</th>\n",
       "      <th>MSLL</th>\n",
       "      <th>BIC</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FA_corpus_callosum</td>\n",
       "      <td>-37554.180136</td>\n",
       "      <td>0.092646</td>\n",
       "      <td>-17.47977</td>\n",
       "      <td>-75069.244948</td>\n",
       "      <td>-0.913438</td>\n",
       "      <td>4.800672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FA_uncinate_fasciculus</td>\n",
       "      <td>-32417.241847</td>\n",
       "      <td>0.026436</td>\n",
       "      <td>-0.01359</td>\n",
       "      <td>-64795.368370</td>\n",
       "      <td>-0.160598</td>\n",
       "      <td>0.772054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eid           NLL        EV      MSLL           BIC  \\\n",
       "0      FA_corpus_callosum -37554.180136  0.092646 -17.47977 -75069.244948   \n",
       "1  FA_uncinate_fasciculus -32417.241847  0.026436  -0.01359 -64795.368370   \n",
       "\n",
       "       Skew  Kurtosis  \n",
       "0 -0.913438  4.800672  \n",
       "1 -0.160598  0.772054  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialise dataframe we will use to store quantitative metrics \n",
    "blr_metrics = pd.DataFrame(columns = ['eid', 'NLL', 'EV', 'MSLL', 'BIC','Skew','Kurtosis'])\n",
    "\n",
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    \n",
    "    # load the predictions and true data. We use a custom function that ensures 2d arrays\n",
    "    # equivalent to: y = np.loadtxt(filename); y = y[:, np.newaxis]\n",
    "    yhat_te = load_2d(os.path.join(idp_dir, 'yhat_' + suffix + '.txt'))\n",
    "    s2_te = load_2d(os.path.join(idp_dir, 'ys2_' + suffix + '.txt'))\n",
    "    y_te = load_2d(os.path.join(idp_dir, 'resp_te.txt'))\n",
    "    \n",
    "    with open(os.path.join(idp_dir,'Models', 'NM_0_0_estimate.pkl'), 'rb') as handle:\n",
    "        nm = pickle.load(handle) \n",
    "    \n",
    "    # compute error metrics\n",
    "    if warp is None:\n",
    "        metrics = evaluate(y_te, yhat_te)  \n",
    "        \n",
    "        # compute MSLL manually as a sanity check\n",
    "        y_tr_mean = np.array( [[np.mean(y_tr)]] )\n",
    "        y_tr_var = np.array( [[np.var(y_tr)]] )\n",
    "        MSLL = compute_MSLL(y_te, yhat_te, s2_te, y_tr_mean, y_tr_var)         \n",
    "    else:\n",
    "        warp_param = nm.blr.hyp[1:nm.blr.warp.get_n_params()+1] \n",
    "        W = nm.blr.warp\n",
    "        \n",
    "        # warp predictions\n",
    "        med_te = W.warp_predictions(np.squeeze(yhat_te), np.squeeze(s2_te), warp_param)[0]\n",
    "        med_te = med_te[:, np.newaxis]\n",
    "       \n",
    "        # evaluation metrics\n",
    "        metrics = evaluate(y_te, med_te)\n",
    "        \n",
    "        # compute MSLL manually\n",
    "        y_te_w = W.f(y_te, warp_param)\n",
    "        y_tr_w = W.f(y_tr, warp_param)\n",
    "        y_tr_mean = np.array( [[np.mean(y_tr_w)]] )\n",
    "        y_tr_var = np.array( [[np.var(y_tr_w)]] )\n",
    "        MSLL = compute_MSLL(y_te_w, yhat_te, s2_te, y_tr_mean, y_tr_var)     \n",
    "    \n",
    "    Z = np.loadtxt(os.path.join(idp_dir, 'Z_' + suffix + '.txt'))\n",
    "    [skew, sdskew, kurtosis, sdkurtosis, semean, sesd] = calibration_descriptives(Z)\n",
    "    \n",
    "    BIC = len(nm.blr.hyp) * np.log(y_tr.shape[0]) + 2 * nm.neg_log_lik\n",
    "    \n",
    "    blr_metrics.loc[len(blr_metrics)] = [idp, nm.neg_log_lik, metrics['EXPV'][0], \n",
    "                                         MSLL[0], BIC, skew, kurtosis]\n",
    "    \n",
    "display(blr_metrics)\n",
    "\n",
    "blr_metrics.to_pickle(os.path.join(out_dir,'blr_metrics.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ids_tr = df_tr.site.unique()\n",
    "site_ids_te = df_te.site.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4998, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(17656, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_te.shape)\n",
    "display(X_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IDP 0 FA_corpus_callosum :\n",
      "All sites are present in the training data\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 1 FA_uncinate_fasciculus :\n",
      "All sites are present in the training data\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n"
     ]
    }
   ],
   "source": [
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    print('Running IDP', idp_num, idp, ':')\n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    os.chdir(idp_dir)\n",
    "    \n",
    "    # extract and save the response variables for the test set\n",
    "    y_te = df_te[idp].to_numpy()\n",
    "    \n",
    "    # save the variables\n",
    "    resp_file_te = os.path.join(idp_dir, 'resp_te.txt') \n",
    "    np.savetxt(resp_file_te, y_te)\n",
    "        \n",
    "    # configure and save the design matrix\n",
    "    cov_file_te = os.path.join(idp_dir, 'cov_bspline_te.txt')\n",
    "    X_te = create_design_matrix(df_te[cols_cov], \n",
    "                                site_ids = df_te['site'],\n",
    "                                all_sites = site_ids_te,\n",
    "                                basis = 'bspline', \n",
    "                                xmin = xmin, \n",
    "                                xmax = xmax)\n",
    "    np.savetxt(cov_file_te, X_te)\n",
    "    \n",
    "    # check whether all sites in the test set are represented in the training set\n",
    "    if all(elem in site_ids_tr for elem in site_ids_te):\n",
    "        print('All sites are present in the training data')\n",
    "        \n",
    "        # just make predictions\n",
    "        yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                                    alg='blr', \n",
    "                                    respfile=resp_file_te, \n",
    "                                    model_path=os.path.join(idp_dir,'Models'))\n",
    "    else:\n",
    "        print('Some sites missing from the training data. Adapting model')\n",
    "        \n",
    "        # save the covariates for the adaptation data\n",
    "        X_ad = create_design_matrix(df_ad[cols_cov], \n",
    "                                    site_ids = df_ad['site'],\n",
    "                                    all_sites = site_ids_tr,\n",
    "                                    basis = 'bspline', \n",
    "                                    xmin = xmin, \n",
    "                                    xmax = xmax)\n",
    "        cov_file_ad = os.path.join(idp_dir, 'cov_bspline_ad.txt')          \n",
    "        np.savetxt(cov_file_ad, X_ad)\n",
    "        \n",
    "        # save the responses for the adaptation data\n",
    "        resp_file_ad = os.path.join(idp_dir, 'resp_ad.txt') \n",
    "        y_ad = df_ad[idp].to_numpy()\n",
    "        np.savetxt(resp_file_ad, y_ad)\n",
    "       \n",
    "        # save the site ids for the adaptation data\n",
    "        sitenum_file_ad = os.path.join(idp_dir, 'sitenum_ad.txt') \n",
    "        site_num_ad = df_ad['sitenum'].to_numpy(dtype=int)\n",
    "        np.savetxt(sitenum_file_ad, site_num_ad)\n",
    "        \n",
    "        # save the site ids for the test data \n",
    "        sitenum_file_te = os.path.join(idp_dir, 'sitenum_te.txt')\n",
    "        site_num_te = df_te['sitenum'].to_numpy(dtype=int)\n",
    "        np.savetxt(sitenum_file_te, site_num_te)\n",
    "         \n",
    "        yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                                    alg = 'blr', \n",
    "                                    respfile = resp_file_te, \n",
    "                                    model_path = os.path.join(idp_dir,'Models'),\n",
    "                                    adaptrespfile = resp_file_ad,\n",
    "                                    adaptcovfile = cov_file_ad,\n",
    "                                    adaptvargroupfile = sitenum_file_ad,\n",
    "                                    testvargroupfile = sitenum_file_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
