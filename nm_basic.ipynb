{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normative modelling for dMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/braincharts/scripts/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from random import sample\n",
    "\n",
    "from pcntoolkit.normative import estimate, predict, evaluate\n",
    "from pcntoolkit.util.utils import compute_MSLL, create_design_matrix\n",
    "from nm_utils import calibration_descriptives, remove_bad_subjects, load_2d\n",
    "\n",
    "ukb_root = '/project_freenas/3022017.02/UKB'\n",
    "sys.path.append(os.path.join(ukb_root,'scripts'))\n",
    "from ukb_utils import get_variables_UKB, lookup_UKB\n",
    "ukb_idp_dir = os.path.join(ukb_root,'phenotypes','current')\n",
    "root_dir = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/braincharts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sex\n",
    "field_codes = ['eid','31-0.0']\n",
    "field_names = ['eid', 'sex']\n",
    "df_sex, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'01_basic_demographics.csv'), field_codes, field_names)\n",
    "\n",
    "# load age and site\n",
    "field_codes = ['eid', '21003-2.0', '54-2.0']\n",
    "field_names = ['eid', 'age', 'site']\n",
    "df_age, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'99_miscellaneous.csv'), field_codes, field_names)\n",
    "\n",
    "# load sex\n",
    "field_codes = ['eid','31-0.0']\n",
    "field_names = ['eid', 'sex']\n",
    "df_sex, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'01_basic_demographics.csv'), field_codes, field_names)\n",
    "\n",
    "# load age and site\n",
    "field_codes = ['eid', '21003-2.0', '54-2.0']\n",
    "field_names = ['eid', 'age', 'site']\n",
    "df_age, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'99_miscellaneous.csv'), field_codes, field_names)\n",
    "\n",
    "# load dMRI derived phenotypes\n",
    "field_codes = ['eid', \n",
    "               '25059-2.0', \n",
    "               '25101-2.0',\n",
    "               '25100-2.0', \n",
    "               '25061-2.0',\n",
    "               '25063-2.0', \n",
    "               '25062-2.0',\n",
    "               '25107-2.0', \n",
    "               '25149-2.0',\n",
    "               '25148-2.0', \n",
    "               '25109-2.0',\n",
    "               '25111-2.0',\n",
    "               '25110-2.0',\n",
    "               '25347-2.0', \n",
    "               '25389-2.0',\n",
    "               '25388-2.0', \n",
    "               '25349-2.0',\n",
    "               '25351-2.0', \n",
    "               '25350-2.0',\n",
    "               '25443-2.0', \n",
    "               '25485-2.0',\n",
    "               '25484-2.0', \n",
    "               '25445-2.0',\n",
    "               '25447-2.0', \n",
    "               '25446-2.0',]\n",
    "field_names = ['eid', \n",
    "               'Mean_FA_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "               'Mean_FA_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "               'Mean_FA_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "               'Mean_FA_in_fornix_on_FA_skeleton',\n",
    "               'Mean_FA_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "               'Mean_FA_in_corticospinal_tract_on_FA_skeleton_right',\n",
    "               'Mean_MD_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "               'Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "               'Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "               'Mean_MD_in_fornix_on_FA_skeleton',\n",
    "               'Mean_MD_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "               'Mean_MD_in_corticospinal_tract_on_FA_skeleton_right',\n",
    "               'Mean_ICVF_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "               'Mean_ICVF_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "               'Mean_ICVF_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "               'Mean_ICVF_in_fornix_on_FA_skeleton',\n",
    "               'Mean_ICVF_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "               'Mean_ICVF_in_corticospinal_tract_on_FA_skeleton_right',\n",
    "               'Mean_ISOVF_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "               'Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "               'Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "               'Mean_ISOVF_in_fornix_on_FA_skeleton',\n",
    "               'Mean_ISOVF_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "               'Mean_ISOVF_in_corticospinal_tract_on_FA_skeleton_right']\n",
    "# field_codes = ['eid','25107-2.0']\n",
    "# field_names = ['eid', 'Mean_MD_in_body_of_corpus_callosum_on_FA_skeleton']\n",
    "df_dmri, subs = get_variables_UKB(os.path.join(ukb_idp_dir,'31_brain_IDPs.csv'), field_codes, field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmri_data = df_sex.join(df_age).join(df_dmri)\n",
    "dmri_data.Mean_MD_in_body_of_corpus_callosum_on_FA_skeleton = dmri_data.Mean_MD_in_body_of_corpus_callosum_on_FA_skeleton*1000\n",
    "dmri_data.Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_left = dmri_data.Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_left*1000\n",
    "dmri_data.Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_right = dmri_data.Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_right*1000\n",
    "dmri_data.Mean_MD_in_fornix_on_FA_skeleton = dmri_data.Mean_MD_in_fornix_on_FA_skeleton*1000\n",
    "dmri_data.Mean_MD_in_corticospinal_tract_on_FA_skeleton_left = dmri_data.Mean_MD_in_corticospinal_tract_on_FA_skeleton_left*1000\n",
    "dmri_data.Mean_MD_in_corticospinal_tract_on_FA_skeleton_right = dmri_data.Mean_MD_in_corticospinal_tract_on_FA_skeleton_right*1000\n",
    "dmri_data.dropna(inplace=True)\n",
    "dmri_data.to_csv(os.path.join(root_dir,'data_dmri.csv'))\n",
    "dmri_data.to_pickle(os.path.join(root_dir,'data_dmri.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 500 subjects sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 labeled sample\n",
    "script_dir = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm'\n",
    "pickled_data = os.path.join(script_dir,'500ukb_qcfeatures.pkl')\n",
    "with open(pickled_data, 'rb') as f: \n",
    "    qc500_features = pickle.load(f)\n",
    "qc500_path = '/home/preclineu/ramcir/Desktop/Diffusion/qc/dMRI/QC_500.csv'\n",
    "qc500_labels = pd.read_csv(qc500_path)\n",
    "qc500_labels[\"Score\"] = [0 if ele > 2 else 1 for ele in qc500_labels[\"Score\"]] # replace 3 scores with 0 and 2's with 1's\n",
    "qc500_labels = qc500_labels.fillna(1) #replace nans with 1s\n",
    "# Select the covariates and IDPs for the 500 subjects with labels\n",
    "df_500sample = dmri_data[dmri_data.index.isin(qc500_labels.ID.astype(str))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23158 subjects in total\n",
      "There are 22658 subjects without manually assigned labels\n",
      "There are 17658 subjects for training\n",
      "There are 5000 subjects for testing\n"
     ]
    }
   ],
   "source": [
    "### Load all the subject IDs that have qc data available\n",
    "pickled_data = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/subjects_qc.pkl'\n",
    "with open(pickled_data, 'rb') as f: \n",
    "    subs_qc = pickle.load(f)\n",
    "### Load the subjects IDs that have manual qc labels available \n",
    "pickled_data = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/labeledsubs_qc.pkl'\n",
    "with open(pickled_data, 'rb') as f: \n",
    "    labeled_qc = pickle.load(f)\n",
    "### Subtract the labeled subs from the total subs\n",
    "keys = list(labeled_qc.columns.values)\n",
    "i1 = subs_qc.set_index(keys).index\n",
    "i2 = labeled_qc.set_index(keys).index\n",
    "unlabeled_subs = subs_qc[~i1.isin(i2)]\n",
    "print('There are', len(subs_qc), 'subjects in total')\n",
    "print('There are', len(unlabeled_subs), 'subjects without manually assigned labels')\n",
    "pickled_data2 = '/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/subs_test_5k.pkl'\n",
    "with open(pickled_data2, 'rb') as f: \n",
    "    subs_test = pickle.load(f)\n",
    "### Create the training subs list\n",
    "keys = list(subs_test.columns.values)\n",
    "i1 = unlabeled_subs.set_index(keys).index\n",
    "i2 = subs_test.set_index(keys).index\n",
    "subs_train = unlabeled_subs[~i1.isin(i2)]\n",
    "print('There are', len(subs_train), 'subjects for training')\n",
    "print('There are', len(subs_test), 'subjects for testing')\n",
    "# subs_train.to_pickle('/home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/subs_train_5k.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testig dataset based on the subject lists\n",
    "df_tr = dmri_data[dmri_data.index.isin(subs_train.subs)]\n",
    "df_te = dmri_data[dmri_data.index.isin(subs_test.subs)]\n",
    "# df_te = df_500sample\n",
    "\n",
    "# with open(os.path.join(root_dir,'data','phenotypes.txt')) as f:\n",
    "#     idp_ids = f.read().splitlines()\n",
    "# idp_ids = ['Mean_FA_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "#            'Mean_FA_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "#            'Mean_FA_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "#            'Mean_FA_in_fornix_on_FA_skeleton',\n",
    "#            'Mean_FA_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "#            'Mean_FA_in_corticospinal_tract_on_FA_skeleton_right',\n",
    "#            'Mean_MD_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "#            'Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "#            'Mean_MD_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "#            'Mean_MD_in_fornix_on_FA_skeleton',\n",
    "#            'Mean_MD_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "#            'Mean_MD_in_corticospinal_tract_on_FA_skeleton_right',\n",
    "#            'Mean_ICVF_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "#            'Mean_ICVF_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "#            'Mean_ICVF_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "#            'Mean_ICVF_in_fornix_on_FA_skeleton',\n",
    "#            'Mean_ICVF_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "#            'Mean_ICVF_in_corticospinal_tract_on_FA_skeleton_right',\n",
    "#            'Mean_ISOVF_in_body_of_corpus_callosum_on_FA_skeleton', \n",
    "#            'Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_left',\n",
    "#            'Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_right',\n",
    "#            'Mean_ISOVF_in_fornix_on_FA_skeleton',\n",
    "#            'Mean_ISOVF_in_corticospinal_tract_on_FA_skeleton_left',\n",
    "#            'Mean_ISOVF_in_corticospinal_tract_on_FA_skeleton_right']\n",
    "idp_ids = ['Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_left'] \n",
    "site_ids =  sorted(set(df_tr['site'].to_list()))\n",
    "\n",
    "# which data columns do we wish to use as covariates? \n",
    "cols_cov = ['age','sex']\n",
    "\n",
    "# which warping function to use? We can set this to None in order to fit a vanilla Gaussian noise model\n",
    "warp =  'WarpSinArcsinh'\n",
    "\n",
    "# limits for cubic B-spline basis \n",
    "xmin = 45 \n",
    "xmax = 85\n",
    "\n",
    "# Do we want to force the model to be refit every time? \n",
    "force_refit = True\n",
    "\n",
    "# Absolute Z treshold above which a sample is considered to be an outlier (without fitting any model)\n",
    "outlier_thresh = 100\n",
    "\n",
    "# where the raw data are stored\n",
    "data_dir = os.path.join(root_dir,'data')\n",
    "\n",
    "# where the analysis takes place\n",
    "out_dir = os.path.join(root_dir,'models','test')\n",
    "\n",
    "# create the output directory if it does not already exist\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IDP 0 Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_left :\n",
      "Estimating the normative model...\n",
      "Processing data in /home/preclineu/ramcir/Desktop/Diffusion/diffusion_nm/braincharts/models/test/Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_left/resp_tr.txt\n",
      "Estimating model  1 of 1\n",
      "configuring BLR ( order 1 )\n",
      "Using default hyperparameters\n",
      "Warning: Estimation of posterior distribution failed\n",
      "Warning: Estimation of posterior distribution failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preclineu/ramcir/.conda/envs/myenv/lib/python3.8/site-packages/pcntoolkit/model/bayesreg.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=7.80896e-20): result may not be accurate.\n",
      "  invAXt = linalg.solve(self.A, X.T, check_finite=False)\n",
      "/home/preclineu/ramcir/.conda/envs/myenv/lib/python3.8/site-packages/pcntoolkit/model/bayesreg.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=5.13446e-20): result may not be accurate.\n",
      "  invAXt = linalg.solve(self.A, X.T, check_finite=False)\n",
      "/home/preclineu/ramcir/.conda/envs/myenv/lib/python3.8/site-packages/pcntoolkit/model/bayesreg.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=1.63146e-20): result may not be accurate.\n",
      "  invAXt = linalg.solve(self.A, X.T, check_finite=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -54049.938873\n",
      "         Iterations: 18\n",
      "         Function evaluations: 974\n",
      "Saving model meta-data...\n",
      "Evaluating the model ...\n",
      "Writing outputs ...\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n"
     ]
    }
   ],
   "source": [
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    print('Running IDP', idp_num, idp, ':')\n",
    "   \n",
    "    # set output dir \n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    os.makedirs(os.path.join(idp_dir), exist_ok=True)\n",
    "    os.chdir(idp_dir)\n",
    "    \n",
    "    # extract the response variables for training and test set\n",
    "    y_tr = df_tr[idp].to_numpy() \n",
    "    y_te = df_te[idp].to_numpy()\n",
    "    \n",
    "    \n",
    "    hyp0 = np.zeros(4)\n",
    "    \n",
    "    \n",
    "    # write out the response variables for training and test\n",
    "    resp_file_tr = os.path.join(idp_dir, 'resp_tr.txt')\n",
    "    resp_file_te = os.path.join(idp_dir, 'resp_te.txt') \n",
    "    np.savetxt(resp_file_tr, y_tr)\n",
    "    np.savetxt(resp_file_te, y_te)\n",
    "        \n",
    "    # configure the design matrix\n",
    "    X_tr = create_design_matrix(df_tr[cols_cov], \n",
    "                                xmin = xmin, \n",
    "                                xmax = xmax)\n",
    "    X_te = create_design_matrix(df_te[cols_cov], \n",
    "                                basis = 'bspline', \n",
    "                                xmin = xmin, \n",
    "                                xmax = xmax)\n",
    "\n",
    "    # configure and save the covariates\n",
    "    cov_file_tr = os.path.join(idp_dir, 'cov_bspline_tr.txt')\n",
    "    cov_file_te = os.path.join(idp_dir, 'cov_bspline_te.txt')\n",
    "    np.savetxt(cov_file_tr, X_tr)\n",
    "    np.savetxt(cov_file_te, X_te)\n",
    "    \n",
    "    suffix = 'predict'\n",
    "    \n",
    "    print('Estimating the normative model...')\n",
    "    estimate(cov_file_tr, resp_file_tr, testresp=resp_file_te, \n",
    "                 testcov=cov_file_te, alg='blr', optimizer = 'powell', l=1000,\n",
    "                 savemodel=True, warp=warp, warp_reparam=True) #'l-bfgs-b'\n",
    "    \n",
    "    suffix = 'estimate'\n",
    "\n",
    "    predict(cov_file_tr, \n",
    "                alg='blr', \n",
    "                respfile=resp_file_tr, \n",
    "                model_path=os.path.join(idp_dir,'Models'),\n",
    "                outputsuffix='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>NLL</th>\n",
       "      <th>EV</th>\n",
       "      <th>MSLL</th>\n",
       "      <th>BIC</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean_ISOVF_in_uncinate_fasciculus_on_FA_skelet...</td>\n",
       "      <td>-54049.938873</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>-0.006734</td>\n",
       "      <td>-108060.762423</td>\n",
       "      <td>0.776509</td>\n",
       "      <td>0.772822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eid           NLL        EV  \\\n",
       "0  Mean_ISOVF_in_uncinate_fasciculus_on_FA_skelet... -54049.938873  0.012615   \n",
       "\n",
       "       MSLL            BIC      Skew  Kurtosis  \n",
       "0 -0.006734 -108060.762423  0.776509  0.772822  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialise dataframe we will use to store quantitative metrics \n",
    "blr_metrics = pd.DataFrame(columns = ['eid', 'NLL', 'EV', 'MSLL', 'BIC','Skew','Kurtosis'])\n",
    "\n",
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    \n",
    "    # load the predictions and true data. We use a custom function that ensures 2d arrays\n",
    "    # equivalent to: y = np.loadtxt(filename); y = y[:, np.newaxis]\n",
    "    yhat_te = load_2d(os.path.join(idp_dir, 'yhat_' + suffix + '.txt'))\n",
    "    s2_te = load_2d(os.path.join(idp_dir, 'ys2_' + suffix + '.txt'))\n",
    "    y_te = load_2d(os.path.join(idp_dir, 'resp_te.txt'))\n",
    "    \n",
    "    with open(os.path.join(idp_dir,'Models', 'NM_0_0_estimate.pkl'), 'rb') as handle:\n",
    "        nm = pickle.load(handle) \n",
    "    \n",
    "    # compute error metrics\n",
    "    if warp is None:\n",
    "        metrics = evaluate(y_te, yhat_te)  \n",
    "        \n",
    "        # compute MSLL manually as a sanity check\n",
    "        y_tr_mean = np.array( [[np.mean(y_tr)]] )\n",
    "        y_tr_var = np.array( [[np.var(y_tr)]] )\n",
    "        MSLL = compute_MSLL(y_te, yhat_te, s2_te, y_tr_mean, y_tr_var)         \n",
    "    else:\n",
    "        warp_param = nm.blr.hyp[1:nm.blr.warp.get_n_params()+1] \n",
    "        W = nm.blr.warp\n",
    "        \n",
    "        # warp predictions\n",
    "        med_te = W.warp_predictions(np.squeeze(yhat_te), np.squeeze(s2_te), warp_param)[0]\n",
    "        med_te = med_te[:, np.newaxis]\n",
    "       \n",
    "        # evaluation metrics\n",
    "        metrics = evaluate(y_te, med_te)\n",
    "        \n",
    "        # compute MSLL manually\n",
    "        y_te_w = W.f(y_te, warp_param)\n",
    "        y_tr_w = W.f(y_tr, warp_param)\n",
    "        y_tr_mean = np.array( [[np.mean(y_tr_w)]] )\n",
    "        y_tr_var = np.array( [[np.var(y_tr_w)]] )\n",
    "        MSLL = compute_MSLL(y_te_w, yhat_te, s2_te, y_tr_mean, y_tr_var)     \n",
    "    \n",
    "    Z = np.loadtxt(os.path.join(idp_dir, 'Z_' + suffix + '.txt'))\n",
    "    [skew, sdskew, kurtosis, sdkurtosis, semean, sesd] = calibration_descriptives(Z)\n",
    "    \n",
    "    BIC = len(nm.blr.hyp) * np.log(y_tr.shape[0]) + 2 * nm.neg_log_lik\n",
    "    \n",
    "    blr_metrics.loc[len(blr_metrics)] = [idp, nm.neg_log_lik, metrics['EXPV'][0], \n",
    "                                         MSLL[0], BIC, skew, kurtosis]\n",
    "    \n",
    "display(blr_metrics)\n",
    "\n",
    "blr_metrics.to_pickle(os.path.join(out_dir,'blr_metrics.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IDP 0 Mean_ISOVF_in_uncinate_fasciculus_on_FA_skeleton_left :\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n"
     ]
    }
   ],
   "source": [
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    print('Running IDP', idp_num, idp, ':')\n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    os.chdir(idp_dir)\n",
    "    \n",
    "    # extract and save the response variables for the test set\n",
    "    y_te = df_te[idp].to_numpy()\n",
    "    y_tr = df_tr[idp].to_numpy()\n",
    "    \n",
    "    # save the variables\n",
    "    resp_file_te = os.path.join(idp_dir, 'resp_te.txt') \n",
    "    np.savetxt(resp_file_te, y_te)\n",
    "    \n",
    "    resp_file_tr = os.path.join(idp_dir, 'resp_tr.txt') \n",
    "    np.savetxt(resp_file_tr, y_tr)\n",
    "    \n",
    "    yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                                    alg='blr', \n",
    "                                    respfile=resp_file_te, \n",
    "                                    model_path=os.path.join(idp_dir,'Models'))\n",
    "    \n",
    "    yhat_tr, s2_tr, Z = predict(cov_file_tr, \n",
    "                                    alg='blr', \n",
    "                                    respfile=resp_file_tr, \n",
    "                                    model_path=os.path.join(idp_dir,'Models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
